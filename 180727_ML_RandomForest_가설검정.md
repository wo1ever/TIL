# 170727

## 오전수업 배로쌤

### 기계학습으로 분류하기

#### 지난 수업 회고

- 차원 축소 - 차원의 저주

  일정한 차원을 ㅈ넘어가면 분류기의 성능이 저점 떨어지고 0으로 수렴.

- 깃헙의 장점

- git stash ' ~ ' (임시저장) / git stash pop (위에꺼부터 하나씩 가져옴) : 소스트리를 사용하면 편함.

  소스트리 이용하면 add 상태를 왔다갔다 할 수 있음.

- git remote -v : fetch / origin 해오는 주소 (보통 똑같은거임)

  til은 origin만 있음.

#### 좋은 커밋 메시지를 작성하는 7가지 방법

1. 제목과 본문을 빈 행으로 분리한다.
2. 제목 행을 50자로 제한한다.
3. 제목 행 첫 글자는 대문자로 쓴다.
4. 제목 행 끝에 마침표를 넣지 않는다.
5. 제목 행에 명령문을 사용한다.
6. 본문을 72자 단위로 개행한다.
7. 어떻게 보다는 무엇과 왜 를 설명한다.

- 터미널에서는 git commit --amend : 커밋메세지 수정 가능(여러 줄로도 가능함.)
- git rebase -i HEAD~3



##### git -flow 브랜치 이해하기

항상 유지되는 메인 브랜치들 (master, develop)과 일정 기간 동안만 유지되는 보조 브랜치들(feature, release, hotfix)

- master: 제품으로 출시될 수 있는 브랜치
- develop: 다음 출시 버전을 개발하는 브랜치
- feature -*: 기능을 개발하는 브랜치
- release-*: 이번 출시 버전을 준비하는 브랜치
- hotfix-* : 출시 버전에서 발생한 버그를 수정하는 브랜치

##### Pull Request 보내기

- commit squash: 오픈소스에 커밋하는 경우 꼭 해주면 좋음. (커밋 메세지 합쳐서 보내기)
- 내가 포크해 온 저장소에서 pull request를 생성해야 함.
- 마크다운 미리보기, 붙여넣기 하는 것도 좋음.
- description을 적어주면 좋음.
- 리뷰어에게 멘션하기
- 풀리퀘 만들때 이슈번호 넣어주기



### 기계학습(Machine Learning)

위키피디아에 있는 내용 참고하기 **[기계 학습 - 위키백과](https://ko.wikipedia.org/wiki/%EA%B8%B0%EA%B3%84_%ED%95%99%EC%8A%B5 )** 

#### 일반화

기계 학습에서의 일반화는 훈련 이후 새롭게 들어온 데이터를 정확히 처리할 수 있는 능력을 말한다.

#### 기계 학습과 데이터 마이닝

기계 학습은 훈련 데이터(Training Data)를 통해 학습된 알려진 속성을 기반으로 예측에 초점을 두고 있다.

데이터 마이닝은 데이터의 미처 몰랐던 속성을 발견하는 것에 집중한다. 이는 데이터베이스의 지식 발견 부분의 분석 절차에 해당한다.

#### Binary Classification

대부분의 캐글 기본 경진대회도 binary로 (0 or 1)

오늘 하는 실습 : 평균보다 높은 추천 수를 받을 것인가, 낮은 추천을 받을 것인가?

측정의 지표로 Type 1 error / Type 2 error 로도 많이 사용함.

#### Over fitting and Under fitting

일반화 : 최대한 아웃라이어 데이터들을 제거해야 함.



##### 오늘 우리가 해야 할 실습 : Random Forest

점수를 높이기 위해 RF의 파라미터를 수정해 볼 수 있음. 여러가지 기법이 있음.

1. 데이터 로드하기
2. 전처리 하기
3. 학습세트와 테스트세트 만들기
4. 단어 벡터화 하기 > 여기까지는 지난시간과 똑같음.
5. 학습시키기
6. 평가하기
7. 예측
8. 개선하기

##### 정확도가 높아지는 조건

데이터 수가 많을 수록

불용어를 잘 제거할 수록







## 오후수업 지현쌤

### 들어가기 전에...

- 회귀분석
  - 예측하고 싶 은 자료(매출액)를 그 자료에 영향을 주는 자료(광고비, 요일, ... )들의 선형 식을 도출하는 것
  - 몇 가지 가정을 만족해야 함.
- 회귀분석과 확률분포
  - 정규분포를 따르지 않을 경우, 정규분포와 같아지게 변환을 해줌.
  - 연속형 변수들 외에 다른 변수들이 있다면 다른 분포들을 가정해 줄 수 있음.
  - 일반화 선형모형 : 여러 다른 분포를 가정하고 회귀분석을 하는 것.
- 회귀분석과 통계적 추론
  - 회귀계수의 값들을 추정치라고 하고, 
  - 표준오차 : 잘못된 정도(오차)를 알려주는것
- 회귀분석과 가설검정
  - 회귀 모형을 설정한 후에는 가설검정을 통해 입증해야 함.

회귀 분석을 할 줄 안다?

=정규분포(확률분포)가 무엇인지 알고있다.

=통계적 추정이 무엇인지 알고있다.

=검정이 무엇인지 알고있다.

### 1. 확률분포

- 통계학과 확률
  - 통계는 표본을 바탕으로 모집단을 추론하는 것
  - 확률 : 근원사건들이 일어날 가능성이 모두 같을 때, 사건이 일어날 확률
  - 확률의 특징:
    - 0~1사이의 값을 갖는다.
    - 모든 사건에 대한 확률의 합은 1이다.
- 이산확률변수와 확률분포 표 : 발생할 사건에 대해 확률을 나열한 것
- 연속확률변수와 률밀도함수 : 확률의 밀도가 어느 구간에 더 높고 어느 구간에 더 낮게 분포하는지를 나타냄. 그 영역이 확률이 됨.

#### 정규분포

- 정규분포의 특징
  - 평균=최빈값=중앙값
  - 평균을 중심으로 좌우대칭
  - 확률이 뮤를 중심으로 2시그마 안에 거의 집중되어 있음(95.4%)
- 정규분포에서 평균과 분산의 특징
  - 평균과 분산에 따라 정규분포 모양이 달라짐.

#### 표준정규분포

- 정규분포의 표준화 : 정규분포에서는 평균과 표준편차에 따라 특정 영역의 넒이가 달라지므로 하나의 기준으로 재배치 해야 함.
- 평균이 0이고 분산이 1일 정규분포를 표준정규분포라고 함.
- 정규분포 관련 함수 실습
  - NORMSDIST(1)=0.84
  - NORMSINV(0.5)=0
  - NORMSINV(0)=error! (엄청작은 무한대)

#### 표집분포

- 통계적 추론

  표본을 통해 모집단을 예측하려면 둘 사이의 연결고리가 필요

  - 모집단(population)의 모수(parameters) : 모집단으로부터 계산된 값
  - 표본(sample)의 통계량(statistics) : 표본으로부터 계산된 모든 값 (일반적으로 통계량을 가지고 모수를 추정함)

- CLT

  모집단의 평균이 뮤이고 분산이 시그마제곱일 때, 임의 추출된 표본의 표본평균(엑스바)는 표본의 크기(n)이 큰 경우(30~100이상) 근사적으로 정규분포를 따르게 되며 그 평균은 뮤이고 표준편차는 시그마/루트엔 이 된다.



### 2. 통계적 추론

#### 통계적 추론

- 통계적 추론의 예

  - 점 추정
  - 구간 추정
  - 가설 검정

- 모평균에 대한 점추정

  - 모수 : 모집단의 평균
  - 자료 : 평균이 뮤, 표준편차가 시그마인 모집단에서 임의추출한 표본
  - 추정량 : 표본평균(엑스바)
  - 표준오차 : s/루트엔 사용

- 표준편차 vs 표준오차

  - 표준편차 : 데이터의 픝어진 정도를 평가하는 도구
  - 표준오차 : 모평균을 추정 시 그 추정량은 표본으로부터 모집단을 추론한 것이기 때문에 완전하지 않음. 그 불완전성에 대한 오차를 의미

- 모평균에 대한 구간추정

  표본의 크기가 크고 평균과 표준편차가 주어질 때 모평균에 대한 95% 신뢰구간

- 통계적 추론에 대한 이해

- "대선 투표율을 72%, 오차는 1%정도" 라는 말은, "100개의 신뢰구간을 구했을 시 그 중 모평균을 포함한 신뢰구간의 수가 95개 정도 된다."는 의미임.

### 3. 가설검정

#### 가설검정

- 검정 예시

  스타벅스의 자바칩 프라푸치노의 칼로리라 340kcal이라고 알려져 있다. 그런데 내가 먹어보니 더 높은 것 같던데? 따라서 전국 스벅 매장에서 랜덤으로 50개의 매장에서 파는 자바 칩 프라푸치노의 칼로리를 측정했다.

  - 모집단 : 스타벅스의 자바 칩 프라푸치노
  - 표본집단 : 무작위로 선택된 50개 매장의 프라푸치노
  - 모수 : 340kcal
  - 통계량 : 50개 자바 칩 프라푸치노의 평균 칼로리
  - **검정하고 싶은 가설** : 스타벅스의 자바 칩 프라푸치노는 340kcal보다 높다.

  

  - 자바 칩 프라푸치노의 칼로리가 340kcal이라고 하기엔 나오기 힘들 정도로 큰 값이 나오면 됨. (충분히 큰 c값을 찾음)

  충분히 큰 값이라고 판단하는 기준?

  - 표준 정규 분포를 이용해 c값을 구할 수 있음

- 가설검정 단계

  1. 가설을 수립

  2. 유의수준 설정

     : 모수의 추정이 맞지 않을 확률을 결정(일반적으로 5%)

  3. 기각역 설정

     : 가설의 기각여부를 결정하는 범위 계산(유의수준에 따른 구간)

  4. 통계량의 계산

     : 표본의 통계량을 이용해 가설검정

  5. 의사결정

     : 기각을 할지 못할지 결정

- 가설의 정의

  : 주어진 사실 혹은 조사하고자 하는 사실이 어떠하다는 주장이나 추측

  - 귀무가설 (H0)

    연구자가 증명하고자 하는 실험가설과 반대되는 입장

    증명되기 전까지는 효과도 없고 차이도 없다는 영가설

    "효과가 없다"

  - 대립가설 (H1)

    귀무가설의 반대로 연구자가 실험을 통해 규명하고자 하는 가설

    "효과가 있다"

- 양측검정과 단측검정

  - 양측검정(two-sided test) 
  - 단측검정(one-sided test)

- 유의수준과 기각역

  - 유의수준(알파) : 귀무가설이 실제로 참일 때, 귀무가설에 대한 판단의 오류 수준
  - 기각역 : 귀무가설을 기각하게 되는 영역

- 모평균에 대한 검정

- 검정통계량과 유의확률

  - 검정통계량 : 가설검정을 위해 사용되는 주요 표본 통계량
  - 유의확률(p-value) : 귀무가설이 맞다는 전제 하에, 통계값이 실제로 관측된 값 이상일 확률

- 유의수준

  왜 유의수준은 10%, 20%가 아니라 5%로 결정하는 것일까?

  - 가설검정에서 내리는 판단은 두 가지

    |           | H0을 기각하지 않음    | H0을 기각함           |
    | --------- | --------------------- | --------------------- |
    | H0이 맞음 | 옳은 결론             | 잘못된 결론(1종 오류) |
    | H0이 틀림 | 잘못된 결론(2종 오류) | 옳은 결론             |

- 1종 오류가 중요한 이유?

  - 신약 개발의 예제
    - 신약기 기존의 약보다 우수하다는것을 입증해야 함
    - 대립가설 : 신약이 기존의 약보다 우수하다. > 새로운 신약으로 변경해야 함.
    - 귀무가설 : 신약이 기존의 약보다 우수하지 않다. > 기존의 신약을 그냥 사용하면 됨.

- ![image](https://user-images.githubusercontent.com/40650004/43309061-a028f480-91be-11e8-9dbd-3b33e7a5af8b.png)

결과 : 유의확률 p-value가 유의수준 5%보다 낮기 때문에 귀무가설을 기각한다. 따라서 '빙상'의 vote수의 평균이 200보다 큼.